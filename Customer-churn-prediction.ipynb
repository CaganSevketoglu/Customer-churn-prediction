{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d95ebf-bdf3-45d8-aea5-0ba54786e00d",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction Project\n",
    "\n",
    "This project predicts customer churn for a fictional telecommunications company. By analyzing customer data, a Logistic Regression model was developed to identify customers likely to cancel their subscriptions, achieving an accuracy of approximately 81.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070c141-8431-4d7e-9cc5-f446fe98c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059756c8-9890-4b03-a696-9db13d605a49",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration\n",
    "\n",
    "The Telco Customer Churn dataset from Kaggle was loaded into a Pandas DataFrame. An initial exploration was performed using `.head()`, `.info()`, and `.describe()` to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76df92-4c24-4a40-b769-8d996f05952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "churn_df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# Display the first 5 rows\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7a8161-01ba-4b82-8dd0-7dab81be2ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of the DataFrame\n",
    "churn_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f3fc9-0fc5-4029-afbf-dd31ccce41f8",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Cleaning\n",
    "\n",
    "In this step, the data was prepared for the model. \n",
    "- The `TotalCharges` column was converted to a numeric type, and missing values were imputed with the column mean.\n",
    "- Binary categorical features (e.g., 'Yes'/'No') were encoded into `1`s and `0`s.\n",
    "- Multi-category features were transformed into numerical format using One-Hot Encoding.\n",
    "- The non-predictive `customerID` column was dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26cb81a-9097-4990-9d90-8d9420497947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix 'TotalCharges' column: convert to numeric and fill missing values\n",
    "churn_df['TotalCharges'] = pd.to_numeric(churn_df['TotalCharges'], errors='coerce')\n",
    "mean_value = churn_df['TotalCharges'].mean()\n",
    "churn_df['TotalCharges'] = churn_df['TotalCharges'].fillna(mean_value)\n",
    "\n",
    "# Encode the target variable 'Churn'\n",
    "churn_df['Churn'] = churn_df['Churn'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Encode other binary categorical columns\n",
    "churn_df['gender'] = churn_df['gender'].map({'Female': 0, 'Male': 1})\n",
    "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
    "for col in binary_cols:\n",
    "    churn_df[col] = churn_df[col].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Apply One-Hot Encoding to multi-category columns\n",
    "multi_cat_cols = churn_df.select_dtypes(include=['object']).columns.drop(['customerID'])\n",
    "churn_df_final = pd.get_dummies(churn_df, columns=multi_cat_cols, drop_first=True)\n",
    "\n",
    "# Drop the non-predictive customerID column\n",
    "churn_df_final = churn_df_final.drop('customerID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517ae84-7056-464b-b8b0-af50e86cec74",
   "metadata": {},
   "source": [
    "## 3. Model Building and Training\n",
    "\n",
    "The dataset was split into features (X) and target (y). It was then divided into training (75%) and testing (25%) sets. The features were scaled using `StandardScaler` to prepare them for the Logistic Regression model, which was then trained on the scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc476fc-664c-4a06-a03c-1c93a3e14552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = churn_df_final.drop('Churn', axis=1)\n",
    "y = churn_df_final['Churn']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ce247-05cc-4390-9f09-eeb0dde87bad",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "The trained model's performance was evaluated on the unseen test data. The model achieved an accuracy of 81.3% and the results were analyzed in detail using a Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3c38ba-abea-4191-a762-3825bdb19aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8132\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1154  128]\n",
      " [ 201  278]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = log_model.score(X_test_scaled, y_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "y_pred = log_model.predict(X_test_scaled)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafd48b2-5368-4544-9539-db38ed8b0e37",
   "metadata": {},
   "source": [
    "### Final Data Check\n",
    "As a final step in preprocessing, let's run the .info() method on our final DataFrame (churn_df_final) to confirm that all columns are now of a numeric data type and ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca1a4141-6ab8-4145-944a-73e9fb8eab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 31 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   gender                                 7043 non-null   int64  \n",
      " 1   SeniorCitizen                          7043 non-null   int64  \n",
      " 2   Partner                                7043 non-null   int64  \n",
      " 3   Dependents                             7043 non-null   int64  \n",
      " 4   tenure                                 7043 non-null   int64  \n",
      " 5   PhoneService                           7043 non-null   int64  \n",
      " 6   PaperlessBilling                       7043 non-null   int64  \n",
      " 7   MonthlyCharges                         7043 non-null   float64\n",
      " 8   TotalCharges                           7043 non-null   float64\n",
      " 9   Churn                                  7043 non-null   int64  \n",
      " 10  MultipleLines_No phone service         7043 non-null   bool   \n",
      " 11  MultipleLines_Yes                      7043 non-null   bool   \n",
      " 12  InternetService_Fiber optic            7043 non-null   bool   \n",
      " 13  InternetService_No                     7043 non-null   bool   \n",
      " 14  OnlineSecurity_No internet service     7043 non-null   bool   \n",
      " 15  OnlineSecurity_Yes                     7043 non-null   bool   \n",
      " 16  OnlineBackup_No internet service       7043 non-null   bool   \n",
      " 17  OnlineBackup_Yes                       7043 non-null   bool   \n",
      " 18  DeviceProtection_No internet service   7043 non-null   bool   \n",
      " 19  DeviceProtection_Yes                   7043 non-null   bool   \n",
      " 20  TechSupport_No internet service        7043 non-null   bool   \n",
      " 21  TechSupport_Yes                        7043 non-null   bool   \n",
      " 22  StreamingTV_No internet service        7043 non-null   bool   \n",
      " 23  StreamingTV_Yes                        7043 non-null   bool   \n",
      " 24  StreamingMovies_No internet service    7043 non-null   bool   \n",
      " 25  StreamingMovies_Yes                    7043 non-null   bool   \n",
      " 26  Contract_One year                      7043 non-null   bool   \n",
      " 27  Contract_Two year                      7043 non-null   bool   \n",
      " 28  PaymentMethod_Credit card (automatic)  7043 non-null   bool   \n",
      " 29  PaymentMethod_Electronic check         7043 non-null   bool   \n",
      " 30  PaymentMethod_Mailed check             7043 non-null   bool   \n",
      "dtypes: bool(21), float64(2), int64(8)\n",
      "memory usage: 694.8 KB\n"
     ]
    }
   ],
   "source": [
    "churn_df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "826b64eb-afce-4f31-9979-4ea13ada7828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Scaler saved successfully to disk.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model object to a file\n",
    "joblib.dump(log_model, 'churn_model.pkl')\n",
    "\n",
    "# Save the scaler object as well, as it's needed to process new data\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Print a confirmation message\n",
    "print(\"Model and Scaler saved successfully to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42283f2f-11d9-4559-8811-c11e77a0e73a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
